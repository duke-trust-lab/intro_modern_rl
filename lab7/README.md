# Lab 7
# Part 2 Human in the Loop RL Lab

### Instructions:
Follow along with the lab notebook, answering the checkpoint questions and filling in the code. 

[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/duke-trust-lab/intro_modern_rl/blob/main/lab7/lab7.ipynb)

### Objectives:
* Train a model using preference-based objectives
* Compare DPO vs KL-regularized RL
* Observe alignment drift and over-optimization
