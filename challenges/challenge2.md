# Challenge 2: Taming the Language Model

Using HuggingFaceâ€™s TRL library or DeepSpeed-Chat, perform an RLHF loop on a toy LLM (e.g., fine-tune completions, docstrings, or QA). You must collect preference data, train a reward model, and apply PPO for alignment. Deliverables include metrics and analysis of misalignment or overoptimization.