# Lab 2
# Tabular RL on FrozenLake: Planning vs Learning

### Instructions:
Follow along with the lab notebook, answering the checkpoint questions and filling in the code. 

[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/duke-trust-lab/intro_modern_rl/blob/main/lab2/lab2.ipynb)

### Objectives:
* Describe an RL problem as an MDP: ⟨S, A, P, R, γ⟩
* Compute an optimal value function using Value Iteration (planning; model-based)
* Learn an optimal action-value function using Q-learning (learning; model-free)
* Explain how both use the same core idea: Bellman optimality backups
